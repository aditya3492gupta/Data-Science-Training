{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2fbf593-f601-496f-8d79-9b6bbf669531",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4956f30-af9d-440c-8cde-8065f4ca73cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.array([2.4,5.0,1.5,3.8,8.7,3.6,1.2,8.1,2.5,5,1.6,1.6,2.4,3.9,5.4])\n",
    "y = np.array([2.1,4.7,1.7,3.6,8.7,3.2,1.0,8.0,2.4,6,1.1,1.3,2.4,3.9,4.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6707035-b8ee-4f01-954d-ce3af3524385",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.29986593263514916 1.6985762977266659\n"
     ]
    }
   ],
   "source": [
    "a0 = 0        # y-intercept\n",
    "a1 = 0        # slope\n",
    "lr = 0.0001   # learning rate\n",
    "iters = 100\n",
    "errors = list()\n",
    "\n",
    "for itr in range(iters):\n",
    "    error_cost = 0\n",
    "    pd_a0 = 0\n",
    "    pd_a1 = 0\n",
    "    for i in range(len(x)):\n",
    "        y_pred_i = a0 + a1 * x[i]\n",
    "        error_cost = error_cost + (y[i] - y_pred_i)**2\n",
    "        for j in range(len(x)):\n",
    "            pd_a0 = pd_a0 + (2 * ((a0 + a1 * x[j]) - y[j]))\n",
    "            pd_a1 = pd_a1 + (2 * x[j] * ((a0 + a1 * x[j]) - y[j]))\n",
    "        a0 = a0 - lr * pd_a0\n",
    "        a1 = a1 - lr * pd_a1\n",
    "    \n",
    "    if itr % 100 == 0:\n",
    "        print(itr, a0, a1)\n",
    "    errors.append(error_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac2ea5e0-31a8-4000-9970-39dd518f0f25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = a0 + a1*x\n",
    "plt.scatter(x, y, color='red')\n",
    "plt.plot(x, y_pred, color='green')\n",
    "plt.xlabel(\"x\")\n",
    "plt.show(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c138d15-6c46-47c2-b695-27566d61b793",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f870c5db050>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1, len(errors)+1), errors, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3162f4ef-9b81-492e-b90a-ef22c256e2d5",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "Batch gradient descent, also known as vanilla gradient descent, calculates the error for each example within the training dataset. Still, the model is not changed until every training sample has been assessed. The entire procedure is referred to as a cycle and a training epoch.\n",
    "\n",
    "Some benefits of batch are its computational efficiency, which produces a stable error gradient and a stable convergence. Some drawbacks are that the stable error gradient can sometimes result in a state of convergence that isn’t the best the model can achieve. It also requires the entire training dataset to be in memory and available to the algorithm.\n",
    "\n",
    "#### Advantages\n",
    "- Fewer model updates mean that this variant of the steepest descent method is more computationally efficient than the stochastic gradient descent method.\n",
    "- Reducing the update frequency provides a more stable error gradient and a more stable convergence for some problems.\n",
    "- Separating forecast error calculations and model updates provides a parallel processing-based algorithm implementation.\n",
    "#### Disadvantages\n",
    "- A more stable error gradient can cause the model to prematurely converge to a suboptimal set of parameters.\n",
    "- End-of-training epoch updates require the additional complexity of accumulating prediction errors across all training examples.\n",
    "- The batch gradient descent method typically requires the entire training dataset in memory and is implemented for use in the algorithm.\n",
    "- Large datasets can result in very slow model updates or training speeds.\n",
    "- Slow and require more computational power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb2f4ae1-470d-4d44-af6d-3e350cd399a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2 - 5*x\n",
    "\n",
    "def df(x):\n",
    "    return 2*x - 5\n",
    "\n",
    "def gradient_descent(f, df, intial_guess, lr=0.01, epsilon=1e-6, max_iteration=1000):\n",
    "    \"\"\"\n",
    "    Gradient Descent optimization algorithm.\n",
    "    \n",
    "    Args:\n",
    "    f (function): The objective function to minimize.\n",
    "    df (function): The gradient (derivative) of the objective function.\n",
    "    initial_guess (array_like): Initial guess for the parameters.\n",
    "    learning_rate (float): Learning rate or step size for the update (default 0.01).\n",
    "    epsilon (float): Convergence criterion. The algorithm stops when the change in\n",
    "        the value of the objective function is less than epsilon (default 1e-6).\n",
    "    max_iterations (int): Maximum number of iterations (default 1000).\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the optimized parameters and the value of the objective function at the optimum.\n",
    "    \"\"\"\n",
    "    x = np.array(initial_guess)\n",
    "    for itr in range(max_iteration):\n",
    "        grad = df(x)\n",
    "        if np.linalg.norm(grad) < epsilon:           # Homework: Explore about this function np.linalg.norm() \n",
    "            break\n",
    "        print(itr, grad)\n",
    "        x = x - lr * grad\n",
    "    return x, f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "511da8aa-6171-4404-91d7-f10ea015a16b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [5]\n",
      "1 [4.9]\n",
      "2 [4.802]\n",
      "3 [4.70596]\n",
      "4 [4.6118408]\n",
      "5 [4.51960398]\n",
      "6 [4.4292119]\n",
      "7 [4.34062767]\n",
      "8 [4.25381511]\n",
      "9 [4.16873881]\n",
      "10 [4.08536403]\n",
      "11 [4.00365675]\n",
      "12 [3.92358362]\n",
      "13 [3.84511195]\n",
      "14 [3.76820971]\n",
      "15 [3.69284551]\n",
      "16 [3.6189886]\n",
      "17 [3.54660883]\n",
      "18 [3.47567665]\n",
      "19 [3.40616312]\n",
      "20 [3.33803986]\n",
      "21 [3.27127906]\n",
      "22 [3.20585348]\n",
      "23 [3.14173641]\n",
      "24 [3.07890168]\n",
      "25 [3.01732365]\n",
      "26 [2.95697718]\n",
      "27 [2.89783763]\n",
      "28 [2.83988088]\n",
      "29 [2.78308326]\n",
      "30 [2.7274216]\n",
      "31 [2.67287316]\n",
      "32 [2.6194157]\n",
      "33 [2.56702739]\n",
      "34 [2.51568684]\n",
      "35 [2.4653731]\n",
      "36 [2.41606564]\n",
      "37 [2.36774433]\n",
      "38 [2.32038944]\n",
      "39 [2.27398165]\n",
      "40 [2.22850202]\n",
      "41 [2.18393198]\n",
      "42 [2.14025334]\n",
      "43 [2.09744827]\n",
      "44 [2.05549931]\n",
      "45 [2.01438932]\n",
      "46 [1.97410153]\n",
      "47 [1.9346195]\n",
      "48 [1.89592711]\n",
      "49 [1.85800857]\n",
      "50 [1.8208484]\n",
      "51 [1.78443143]\n",
      "52 [1.7487428]\n",
      "53 [1.71376795]\n",
      "54 [1.67949259]\n",
      "55 [1.64590274]\n",
      "56 [1.61298468]\n",
      "57 [1.58072499]\n",
      "58 [1.54911049]\n",
      "59 [1.51812828]\n",
      "60 [1.48776571]\n",
      "61 [1.4580104]\n",
      "62 [1.42885019]\n",
      "63 [1.40027319]\n",
      "64 [1.37226772]\n",
      "65 [1.34482237]\n",
      "66 [1.31792592]\n",
      "67 [1.2915674]\n",
      "68 [1.26573606]\n",
      "69 [1.24042133]\n",
      "70 [1.21561291]\n",
      "71 [1.19130065]\n",
      "72 [1.16747464]\n",
      "73 [1.14412514]\n",
      "74 [1.12124264]\n",
      "75 [1.09881779]\n",
      "76 [1.07684143]\n",
      "77 [1.0553046]\n",
      "78 [1.03419851]\n",
      "79 [1.01351454]\n",
      "80 [0.99324425]\n",
      "81 [0.97337937]\n",
      "82 [0.95391178]\n",
      "83 [0.93483354]\n",
      "84 [0.91613687]\n",
      "85 [0.89781413]\n",
      "86 [0.87985785]\n",
      "87 [0.86226069]\n",
      "88 [0.84501548]\n",
      "89 [0.82811517]\n",
      "90 [0.81155287]\n",
      "91 [0.79532181]\n",
      "92 [0.77941537]\n",
      "93 [0.76382707]\n",
      "94 [0.74855053]\n",
      "95 [0.73357951]\n",
      "96 [0.71890792]\n",
      "97 [0.70452977]\n",
      "98 [0.69043917]\n",
      "99 [0.67663039]\n",
      "100 [0.66309778]\n",
      "101 [0.64983582]\n",
      "102 [0.63683911]\n",
      "103 [0.62410233]\n",
      "104 [0.61162028]\n",
      "105 [0.59938787]\n",
      "106 [0.58740012]\n",
      "107 [0.57565211]\n",
      "108 [0.56413907]\n",
      "109 [0.55285629]\n",
      "110 [0.54179916]\n",
      "111 [0.53096318]\n",
      "112 [0.52034392]\n",
      "113 [0.50993704]\n",
      "114 [0.4997383]\n",
      "115 [0.48974353]\n",
      "116 [0.47994866]\n",
      "117 [0.47034969]\n",
      "118 [0.46094269]\n",
      "119 [0.45172384]\n",
      "120 [0.44268936]\n",
      "121 [0.43383558]\n",
      "122 [0.42515886]\n",
      "123 [0.41665569]\n",
      "124 [0.40832257]\n",
      "125 [0.40015612]\n",
      "126 [0.392153]\n",
      "127 [0.38430994]\n",
      "128 [0.37662374]\n",
      "129 [0.36909127]\n",
      "130 [0.36170944]\n",
      "131 [0.35447525]\n",
      "132 [0.34738575]\n",
      "133 [0.34043803]\n",
      "134 [0.33362927]\n",
      "135 [0.32695669]\n",
      "136 [0.32041755]\n",
      "137 [0.3140092]\n",
      "138 [0.30772902]\n",
      "139 [0.30157444]\n",
      "140 [0.29554295]\n",
      "141 [0.28963209]\n",
      "142 [0.28383945]\n",
      "143 [0.27816266]\n",
      "144 [0.27259941]\n",
      "145 [0.26714742]\n",
      "146 [0.26180447]\n",
      "147 [0.25656838]\n",
      "148 [0.25143701]\n",
      "149 [0.24640827]\n",
      "150 [0.24148011]\n",
      "151 [0.2366505]\n",
      "152 [0.23191749]\n",
      "153 [0.22727914]\n",
      "154 [0.22273356]\n",
      "155 [0.21827889]\n",
      "156 [0.21391331]\n",
      "157 [0.20963505]\n",
      "158 [0.20544235]\n",
      "159 [0.2013335]\n",
      "160 [0.19730683]\n",
      "161 [0.19336069]\n",
      "162 [0.18949348]\n",
      "163 [0.18570361]\n",
      "164 [0.18198954]\n",
      "165 [0.17834975]\n",
      "166 [0.17478275]\n",
      "167 [0.1712871]\n",
      "168 [0.16786135]\n",
      "169 [0.16450413]\n",
      "170 [0.16121404]\n",
      "171 [0.15798976]\n",
      "172 [0.15482997]\n",
      "173 [0.15173337]\n",
      "174 [0.1486987]\n",
      "175 [0.14572473]\n",
      "176 [0.14281023]\n",
      "177 [0.13995403]\n",
      "178 [0.13715495]\n",
      "179 [0.13441185]\n",
      "180 [0.13172361]\n",
      "181 [0.12908914]\n",
      "182 [0.12650736]\n",
      "183 [0.12397721]\n",
      "184 [0.12149767]\n",
      "185 [0.11906771]\n",
      "186 [0.11668636]\n",
      "187 [0.11435263]\n",
      "188 [0.11206558]\n",
      "189 [0.10982427]\n",
      "190 [0.10762778]\n",
      "191 [0.10547523]\n",
      "192 [0.10336572]\n",
      "193 [0.10129841]\n",
      "194 [0.09927244]\n",
      "195 [0.09728699]\n",
      "196 [0.09534125]\n",
      "197 [0.09343442]\n",
      "198 [0.09156574]\n",
      "199 [0.08973442]\n",
      "200 [0.08793973]\n",
      "201 [0.08618094]\n",
      "202 [0.08445732]\n",
      "203 [0.08276817]\n",
      "204 [0.08111281]\n",
      "205 [0.07949055]\n",
      "206 [0.07790074]\n",
      "207 [0.07634273]\n",
      "208 [0.07481587]\n",
      "209 [0.07331956]\n",
      "210 [0.07185316]\n",
      "211 [0.0704161]\n",
      "212 [0.06900778]\n",
      "213 [0.06762762]\n",
      "214 [0.06627507]\n",
      "215 [0.06494957]\n",
      "216 [0.06365058]\n",
      "217 [0.06237757]\n",
      "218 [0.06113002]\n",
      "219 [0.05990742]\n",
      "220 [0.05870927]\n",
      "221 [0.05753508]\n",
      "222 [0.05638438]\n",
      "223 [0.05525669]\n",
      "224 [0.05415156]\n",
      "225 [0.05306853]\n",
      "226 [0.05200716]\n",
      "227 [0.05096701]\n",
      "228 [0.04994767]\n",
      "229 [0.04894872]\n",
      "230 [0.04796975]\n",
      "231 [0.04701035]\n",
      "232 [0.04607014]\n",
      "233 [0.04514874]\n",
      "234 [0.04424577]\n",
      "235 [0.04336085]\n",
      "236 [0.04249363]\n",
      "237 [0.04164376]\n",
      "238 [0.04081089]\n",
      "239 [0.03999467]\n",
      "240 [0.03919477]\n",
      "241 [0.03841088]\n",
      "242 [0.03764266]\n",
      "243 [0.03688981]\n",
      "244 [0.03615201]\n",
      "245 [0.03542897]\n",
      "246 [0.03472039]\n",
      "247 [0.03402598]\n",
      "248 [0.03334546]\n",
      "249 [0.03267856]\n",
      "250 [0.03202498]\n",
      "251 [0.03138448]\n",
      "252 [0.0307568]\n",
      "253 [0.03014166]\n",
      "254 [0.02953883]\n",
      "255 [0.02894805]\n",
      "256 [0.02836909]\n",
      "257 [0.02780171]\n",
      "258 [0.02724567]\n",
      "259 [0.02670076]\n",
      "260 [0.02616674]\n",
      "261 [0.02564341]\n",
      "262 [0.02513054]\n",
      "263 [0.02462793]\n",
      "264 [0.02413537]\n",
      "265 [0.02365266]\n",
      "266 [0.02317961]\n",
      "267 [0.02271602]\n",
      "268 [0.0222617]\n",
      "269 [0.02181646]\n",
      "270 [0.02138013]\n",
      "271 [0.02095253]\n",
      "272 [0.02053348]\n",
      "273 [0.02012281]\n",
      "274 [0.01972036]\n",
      "275 [0.01932595]\n",
      "276 [0.01893943]\n",
      "277 [0.01856064]\n",
      "278 [0.01818943]\n",
      "279 [0.01782564]\n",
      "280 [0.01746913]\n",
      "281 [0.01711974]\n",
      "282 [0.01677735]\n",
      "283 [0.0164418]\n",
      "284 [0.01611297]\n",
      "285 [0.01579071]\n",
      "286 [0.01547489]\n",
      "287 [0.0151654]\n",
      "288 [0.01486209]\n",
      "289 [0.01456485]\n",
      "290 [0.01427355]\n",
      "291 [0.01398808]\n",
      "292 [0.01370832]\n",
      "293 [0.01343415]\n",
      "294 [0.01316547]\n",
      "295 [0.01290216]\n",
      "296 [0.01264411]\n",
      "297 [0.01239123]\n",
      "298 [0.01214341]\n",
      "299 [0.01190054]\n",
      "300 [0.01166253]\n",
      "301 [0.01142928]\n",
      "302 [0.01120069]\n",
      "303 [0.01097668]\n",
      "304 [0.01075714]\n",
      "305 [0.010542]\n",
      "306 [0.01033116]\n",
      "307 [0.01012454]\n",
      "308 [0.00992205]\n",
      "309 [0.00972361]\n",
      "310 [0.00952913]\n",
      "311 [0.00933855]\n",
      "312 [0.00915178]\n",
      "313 [0.00896875]\n",
      "314 [0.00878937]\n",
      "315 [0.00861358]\n",
      "316 [0.00844131]\n",
      "317 [0.00827249]\n",
      "318 [0.00810704]\n",
      "319 [0.00794489]\n",
      "320 [0.007786]\n",
      "321 [0.00763028]\n",
      "322 [0.00747767]\n",
      "323 [0.00732812]\n",
      "324 [0.00718156]\n",
      "325 [0.00703792]\n",
      "326 [0.00689717]\n",
      "327 [0.00675922]\n",
      "328 [0.00662404]\n",
      "329 [0.00649156]\n",
      "330 [0.00636173]\n",
      "331 [0.00623449]\n",
      "332 [0.0061098]\n",
      "333 [0.00598761]\n",
      "334 [0.00586785]\n",
      "335 [0.0057505]\n",
      "336 [0.00563549]\n",
      "337 [0.00552278]\n",
      "338 [0.00541232]\n",
      "339 [0.00530408]\n",
      "340 [0.00519799]\n",
      "341 [0.00509403]\n",
      "342 [0.00499215]\n",
      "343 [0.00489231]\n",
      "344 [0.00479446]\n",
      "345 [0.00469857]\n",
      "346 [0.0046046]\n",
      "347 [0.00451251]\n",
      "348 [0.00442226]\n",
      "349 [0.00433382]\n",
      "350 [0.00424714]\n",
      "351 [0.0041622]\n",
      "352 [0.00407895]\n",
      "353 [0.00399737]\n",
      "354 [0.00391743]\n",
      "355 [0.00383908]\n",
      "356 [0.0037623]\n",
      "357 [0.00368705]\n",
      "358 [0.00361331]\n",
      "359 [0.00354104]\n",
      "360 [0.00347022]\n",
      "361 [0.00340082]\n",
      "362 [0.0033328]\n",
      "363 [0.00326615]\n",
      "364 [0.00320082]\n",
      "365 [0.00313681]\n",
      "366 [0.00307407]\n",
      "367 [0.00301259]\n",
      "368 [0.00295234]\n",
      "369 [0.00289329]\n",
      "370 [0.00283542]\n",
      "371 [0.00277872]\n",
      "372 [0.00272314]\n",
      "373 [0.00266868]\n",
      "374 [0.0026153]\n",
      "375 [0.002563]\n",
      "376 [0.00251174]\n",
      "377 [0.0024615]\n",
      "378 [0.00241227]\n",
      "379 [0.00236403]\n",
      "380 [0.00231675]\n",
      "381 [0.00227041]\n",
      "382 [0.002225]\n",
      "383 [0.0021805]\n",
      "384 [0.00213689]\n",
      "385 [0.00209416]\n",
      "386 [0.00205227]\n",
      "387 [0.00201123]\n",
      "388 [0.001971]\n",
      "389 [0.00193158]\n",
      "390 [0.00189295]\n",
      "391 [0.00185509]\n",
      "392 [0.00181799]\n",
      "393 [0.00178163]\n",
      "394 [0.001746]\n",
      "395 [0.00171108]\n",
      "396 [0.00167686]\n",
      "397 [0.00164332]\n",
      "398 [0.00161045]\n",
      "399 [0.00157824]\n",
      "400 [0.00154668]\n",
      "401 [0.00151575]\n",
      "402 [0.00148543]\n",
      "403 [0.00145572]\n",
      "404 [0.00142661]\n",
      "405 [0.00139808]\n",
      "406 [0.00137011]\n",
      "407 [0.00134271]\n",
      "408 [0.00131586]\n",
      "409 [0.00128954]\n",
      "410 [0.00126375]\n",
      "411 [0.00123847]\n",
      "412 [0.00121371]\n",
      "413 [0.00118943]\n",
      "414 [0.00116564]\n",
      "415 [0.00114233]\n",
      "416 [0.00111948]\n",
      "417 [0.00109709]\n",
      "418 [0.00107515]\n",
      "419 [0.00105365]\n",
      "420 [0.00103258]\n",
      "421 [0.00101192]\n",
      "422 [0.00099169]\n",
      "423 [0.00097185]\n",
      "424 [0.00095241]\n",
      "425 [0.00093337]\n",
      "426 [0.0009147]\n",
      "427 [0.00089641]\n",
      "428 [0.00087848]\n",
      "429 [0.00086091]\n",
      "430 [0.00084369]\n",
      "431 [0.00082682]\n",
      "432 [0.00081028]\n",
      "433 [0.00079407]\n",
      "434 [0.00077819]\n",
      "435 [0.00076263]\n",
      "436 [0.00074738]\n",
      "437 [0.00073243]\n",
      "438 [0.00071778]\n",
      "439 [0.00070342]\n",
      "440 [0.00068936]\n",
      "441 [0.00067557]\n",
      "442 [0.00066206]\n",
      "443 [0.00064882]\n",
      "444 [0.00063584]\n",
      "445 [0.00062312]\n",
      "446 [0.00061066]\n",
      "447 [0.00059845]\n",
      "448 [0.00058648]\n",
      "449 [0.00057475]\n",
      "450 [0.00056325]\n",
      "451 [0.00055199]\n",
      "452 [0.00054095]\n",
      "453 [0.00053013]\n",
      "454 [0.00051953]\n",
      "455 [0.00050914]\n",
      "456 [0.00049895]\n",
      "457 [0.00048897]\n",
      "458 [0.0004792]\n",
      "459 [0.00046961]\n",
      "460 [0.00046022]\n",
      "461 [0.00045101]\n",
      "462 [0.00044199]\n",
      "463 [0.00043315]\n",
      "464 [0.00042449]\n",
      "465 [0.000416]\n",
      "466 [0.00040768]\n",
      "467 [0.00039953]\n",
      "468 [0.00039154]\n",
      "469 [0.00038371]\n",
      "470 [0.00037603]\n",
      "471 [0.00036851]\n",
      "472 [0.00036114]\n",
      "473 [0.00035392]\n",
      "474 [0.00034684]\n",
      "475 [0.0003399]\n",
      "476 [0.00033311]\n",
      "477 [0.00032644]\n",
      "478 [0.00031991]\n",
      "479 [0.00031352]\n",
      "480 [0.00030725]\n",
      "481 [0.0003011]\n",
      "482 [0.00029508]\n",
      "483 [0.00028918]\n",
      "484 [0.00028339]\n",
      "485 [0.00027773]\n",
      "486 [0.00027217]\n",
      "487 [0.00026673]\n",
      "488 [0.00026139]\n",
      "489 [0.00025617]\n",
      "490 [0.00025104]\n",
      "491 [0.00024602]\n",
      "492 [0.0002411]\n",
      "493 [0.00023628]\n",
      "494 [0.00023155]\n",
      "495 [0.00022692]\n",
      "496 [0.00022238]\n",
      "497 [0.00021794]\n",
      "498 [0.00021358]\n",
      "499 [0.00020931]\n",
      "500 [0.00020512]\n",
      "501 [0.00020102]\n",
      "502 [0.000197]\n",
      "503 [0.00019306]\n",
      "504 [0.0001892]\n",
      "505 [0.00018541]\n",
      "506 [0.0001817]\n",
      "507 [0.00017807]\n",
      "508 [0.00017451]\n",
      "509 [0.00017102]\n",
      "510 [0.0001676]\n",
      "511 [0.00016425]\n",
      "512 [0.00016096]\n",
      "513 [0.00015774]\n",
      "514 [0.00015459]\n",
      "515 [0.0001515]\n",
      "516 [0.00014847]\n",
      "517 [0.0001455]\n",
      "518 [0.00014259]\n",
      "519 [0.00013973]\n",
      "520 [0.00013694]\n",
      "521 [0.0001342]\n",
      "522 [0.00013152]\n",
      "523 [0.00012889]\n",
      "524 [0.00012631]\n",
      "525 [0.00012378]\n",
      "526 [0.00012131]\n",
      "527 [0.00011888]\n",
      "528 [0.0001165]\n",
      "529 [0.00011417]\n",
      "530 [0.00011189]\n",
      "531 [0.00010965]\n",
      "532 [0.00010746]\n",
      "533 [0.00010531]\n",
      "534 [0.0001032]\n",
      "535 [0.00010114]\n",
      "536 [9.9116641e-05]\n",
      "537 [9.71343081e-05]\n",
      "538 [9.5191622e-05]\n",
      "539 [9.32877895e-05]\n",
      "540 [9.14220338e-05]\n",
      "541 [8.95935931e-05]\n",
      "542 [8.78017212e-05]\n",
      "543 [8.60456868e-05]\n",
      "544 [8.43247731e-05]\n",
      "545 [8.26382776e-05]\n",
      "546 [8.0985512e-05]\n",
      "547 [7.93658018e-05]\n",
      "548 [7.77784858e-05]\n",
      "549 [7.62229161e-05]\n",
      "550 [7.46984577e-05]\n",
      "551 [7.32044886e-05]\n",
      "552 [7.17403988e-05]\n",
      "553 [7.03055908e-05]\n",
      "554 [6.8899479e-05]\n",
      "555 [6.75214894e-05]\n",
      "556 [6.61710596e-05]\n",
      "557 [6.48476385e-05]\n",
      "558 [6.35506857e-05]\n",
      "559 [6.2279672e-05]\n",
      "560 [6.10340785e-05]\n",
      "561 [5.9813397e-05]\n",
      "562 [5.8617129e-05]\n",
      "563 [5.74447864e-05]\n",
      "564 [5.62958907e-05]\n",
      "565 [5.51699729e-05]\n",
      "566 [5.40665734e-05]\n",
      "567 [5.2985242e-05]\n",
      "568 [5.19255371e-05]\n",
      "569 [5.08870264e-05]\n",
      "570 [4.98692859e-05]\n",
      "571 [4.88719001e-05]\n",
      "572 [4.78944621e-05]\n",
      "573 [4.69365729e-05]\n",
      "574 [4.59978414e-05]\n",
      "575 [4.50778846e-05]\n",
      "576 [4.41763269e-05]\n",
      "577 [4.32928004e-05]\n",
      "578 [4.24269444e-05]\n",
      "579 [4.15784055e-05]\n",
      "580 [4.07468374e-05]\n",
      "581 [3.99319006e-05]\n",
      "582 [3.91332626e-05]\n",
      "583 [3.83505974e-05]\n",
      "584 [3.75835854e-05]\n",
      "585 [3.68319137e-05]\n",
      "586 [3.60952754e-05]\n",
      "587 [3.53733699e-05]\n",
      "588 [3.46659025e-05]\n",
      "589 [3.39725845e-05]\n",
      "590 [3.32931328e-05]\n",
      "591 [3.26272701e-05]\n",
      "592 [3.19747247e-05]\n",
      "593 [3.13352302e-05]\n",
      "594 [3.07085256e-05]\n",
      "595 [3.00943551e-05]\n",
      "596 [2.9492468e-05]\n",
      "597 [2.89026187e-05]\n",
      "598 [2.83245663e-05]\n",
      "599 [2.7758075e-05]\n",
      "600 [2.72029135e-05]\n",
      "601 [2.66588552e-05]\n",
      "602 [2.61256781e-05]\n",
      "603 [2.56031645e-05]\n",
      "604 [2.50911012e-05]\n",
      "605 [2.45892792e-05]\n",
      "606 [2.40974936e-05]\n",
      "607 [2.36155437e-05]\n",
      "608 [2.31432329e-05]\n",
      "609 [2.26803682e-05]\n",
      "610 [2.22267609e-05]\n",
      "611 [2.17822256e-05]\n",
      "612 [2.13465811e-05]\n",
      "613 [2.09196495e-05]\n",
      "614 [2.05012565e-05]\n",
      "615 [2.00912314e-05]\n",
      "616 [1.96894068e-05]\n",
      "617 [1.92956186e-05]\n",
      "618 [1.89097062e-05]\n",
      "619 [1.85315121e-05]\n",
      "620 [1.81608819e-05]\n",
      "621 [1.77976642e-05]\n",
      "622 [1.7441711e-05]\n",
      "623 [1.70928767e-05]\n",
      "624 [1.67510192e-05]\n",
      "625 [1.64159988e-05]\n",
      "626 [1.60876788e-05]\n",
      "627 [1.57659253e-05]\n",
      "628 [1.54506068e-05]\n",
      "629 [1.51415946e-05]\n",
      "630 [1.48387627e-05]\n",
      "631 [1.45419875e-05]\n",
      "632 [1.42511477e-05]\n",
      "633 [1.39661248e-05]\n",
      "634 [1.36868023e-05]\n",
      "635 [1.34130662e-05]\n",
      "636 [1.31448049e-05]\n",
      "637 [1.28819088e-05]\n",
      "638 [1.26242706e-05]\n",
      "639 [1.23717852e-05]\n",
      "640 [1.21243495e-05]\n",
      "641 [1.18818625e-05]\n",
      "642 [1.16442253e-05]\n",
      "643 [1.14113408e-05]\n",
      "644 [1.1183114e-05]\n",
      "645 [1.09594517e-05]\n",
      "646 [1.07402626e-05]\n",
      "647 [1.05254574e-05]\n",
      "648 [1.03149482e-05]\n",
      "649 [1.01086493e-05]\n",
      "650 [9.90647629e-06]\n",
      "651 [9.70834676e-06]\n",
      "652 [9.51417983e-06]\n",
      "653 [9.32389623e-06]\n",
      "654 [9.13741831e-06]\n",
      "655 [8.95466994e-06]\n",
      "656 [8.77557654e-06]\n",
      "657 [8.60006501e-06]\n",
      "658 [8.42806371e-06]\n",
      "659 [8.25950244e-06]\n",
      "660 [8.09431239e-06]\n",
      "661 [7.93242614e-06]\n",
      "662 [7.77377762e-06]\n",
      "663 [7.61830207e-06]\n",
      "664 [7.46593602e-06]\n",
      "665 [7.3166173e-06]\n",
      "666 [7.17028496e-06]\n",
      "667 [7.02687926e-06]\n",
      "668 [6.88634167e-06]\n",
      "669 [6.74861484e-06]\n",
      "670 [6.61364254e-06]\n",
      "671 [6.48136969e-06]\n",
      "672 [6.3517423e-06]\n",
      "673 [6.22470745e-06]\n",
      "674 [6.1002133e-06]\n",
      "675 [5.97820904e-06]\n",
      "676 [5.85864486e-06]\n",
      "677 [5.74147196e-06]\n",
      "678 [5.62664252e-06]\n",
      "679 [5.51410967e-06]\n",
      "680 [5.40382748e-06]\n",
      "681 [5.29575093e-06]\n",
      "682 [5.18983591e-06]\n",
      "683 [5.08603919e-06]\n",
      "684 [4.98431841e-06]\n",
      "685 [4.88463204e-06]\n",
      "686 [4.7869394e-06]\n",
      "687 [4.69120061e-06]\n",
      "688 [4.5973766e-06]\n",
      "689 [4.50542907e-06]\n",
      "690 [4.41532048e-06]\n",
      "691 [4.32701408e-06]\n",
      "692 [4.24047379e-06]\n",
      "693 [4.15566432e-06]\n",
      "694 [4.07255103e-06]\n",
      "695 [3.99110001e-06]\n",
      "696 [3.91127801e-06]\n",
      "697 [3.83305245e-06]\n",
      "698 [3.7563914e-06]\n",
      "699 [3.68126357e-06]\n",
      "700 [3.6076383e-06]\n",
      "701 [3.53548553e-06]\n",
      "702 [3.46477582e-06]\n",
      "703 [3.39548031e-06]\n",
      "704 [3.3275707e-06]\n",
      "705 [3.26101929e-06]\n",
      "706 [3.1957989e-06]\n",
      "707 [3.13188292e-06]\n",
      "708 [3.06924526e-06]\n",
      "709 [3.00786036e-06]\n",
      "710 [2.94770315e-06]\n",
      "711 [2.88874909e-06]\n",
      "712 [2.83097411e-06]\n",
      "713 [2.77435462e-06]\n",
      "714 [2.71886753e-06]\n",
      "715 [2.66449018e-06]\n",
      "716 [2.61120038e-06]\n",
      "717 [2.55897637e-06]\n",
      "718 [2.50779684e-06]\n",
      "719 [2.45764091e-06]\n",
      "720 [2.40848809e-06]\n",
      "721 [2.36031833e-06]\n",
      "722 [2.31311196e-06]\n",
      "723 [2.26684972e-06]\n",
      "724 [2.22151273e-06]\n",
      "725 [2.17708247e-06]\n",
      "726 [2.13354082e-06]\n",
      "727 [2.09087001e-06]\n",
      "728 [2.04905261e-06]\n",
      "729 [2.00807155e-06]\n",
      "730 [1.96791012e-06]\n",
      "731 [1.92855192e-06]\n",
      "732 [1.88998088e-06]\n",
      "733 [1.85218126e-06]\n",
      "734 [1.81513764e-06]\n",
      "735 [1.77883489e-06]\n",
      "736 [1.74325819e-06]\n",
      "737 [1.70839302e-06]\n",
      "738 [1.67422516e-06]\n",
      "739 [1.64074066e-06]\n",
      "740 [1.60792585e-06]\n",
      "741 [1.57576733e-06]\n",
      "742 [1.54425198e-06]\n",
      "743 [1.51336694e-06]\n",
      "744 [1.48309961e-06]\n",
      "745 [1.45343761e-06]\n",
      "746 [1.42436886e-06]\n",
      "747 [1.39588149e-06]\n",
      "748 [1.36796386e-06]\n",
      "749 [1.34060458e-06]\n",
      "750 [1.31379249e-06]\n",
      "751 [1.28751664e-06]\n",
      "752 [1.2617663e-06]\n",
      "753 [1.23653098e-06]\n",
      "754 [1.21180036e-06]\n",
      "755 [1.18756435e-06]\n",
      "756 [1.16381306e-06]\n",
      "757 [1.1405368e-06]\n",
      "758 [1.11772607e-06]\n",
      "759 [1.09537155e-06]\n",
      "760 [1.07346412e-06]\n",
      "761 [1.05199483e-06]\n",
      "762 [1.03095494e-06]\n",
      "763 [1.01033584e-06]\n",
      "[2.5000005] [-6.25]\n"
     ]
    }
   ],
   "source": [
    "initial_guess = [5]\n",
    "\n",
    "optimal_param, min_value = gradient_descent(f, df, initial_guess)\n",
    "\n",
    "print(optimal_param, min_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6839414-ffcc-473a-b9a3-267c0875ea4c",
   "metadata": {},
   "source": [
    "https://jermwatt.github.io/machine_learning_refined/notes/16_Linear_algebra/16_5_Norms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df6d58-a88f-4b17-9d3e-bbd8c2ea8edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03e06172-d71b-497e-a616-229f84120e8a",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "\n",
    "By contrast, stochastic gradient descent (SGD) changes the parameters for each training sample one at a time for each training example in the dataset. Depending on the issue, this can make SGD faster than batch gradient descent. One benefit is that the regular updates give us a fairly accurate idea of the rate of improvement.\n",
    "\n",
    "However, the batch approach is less computationally expensive than the frequent updates. The frequency of such updates can also produce noisy gradients, which could cause the error rate to fluctuate rather than gradually go down.\n",
    "\n",
    "#### Advantages\n",
    "- You can instantly see your model’s performance and improvement rates with frequent updates.\n",
    "- This variant of the steepest descent method is probably the easiest to understand and implement, especially for beginners.\n",
    "- Increasing the frequency of model updates will allow you to learn more about some issues faster.\n",
    "- The noisy update process allows the model to avoid local minima (e.g., premature convergence).\n",
    "- Faster and require less computational power.\n",
    "- Suitable for the larger dataset.\n",
    "#### Disadvantages\n",
    "- Frequent model updates are more computationally intensive than other steepest descent configurations, and it takes considerable time to train the model with large datasets.\n",
    "- Frequent updates can result in noisy gradient signals. This can result in model parameters and cause errors to fly around (more variance across the training epoch).\n",
    "- A noisy learning process along the error gradient can also make it difficult for the algorithm to commit to the model’s minimum error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8adad18d-cc3b-4c82-88c0-470334c3c757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return (x+1)**2 + 34\n",
    "\n",
    "def df(x, data_point):\n",
    "    return 2*(x+1)*data_point        # We are multiplying the squared loss error on the data_point with respect to x\n",
    "\n",
    "def sgd(f, df, initial_guess, dataset, lr=0.01, epsilon=1e-6, max_iterations=1000):\n",
    "    \"\"\"\n",
    "    Stochastic Gradient Descent optimization algorithm.\n",
    "    \n",
    "    Args:\n",
    "    f (function): The objective function to minimize.\n",
    "    df (function): The gradient (derivative) of the objective function.\n",
    "    initial_guess (array_like): Initial guess for the parameters.\n",
    "    dataset (array_like): The dataset for stochastic updates.\n",
    "    learning_rate (float): Learning rate or step size for the update (default 0.01).\n",
    "    epsilon (float): Convergence criterion. The algorithm stops when the change in\n",
    "        the value of the objective function is less than epsilon (default 1e-6).\n",
    "    max_iterations (int): Maximum number of iterations (default 1000).\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the optimized parameters and the value of the objective function at the optimum.\n",
    "    \"\"\"\n",
    "    x = np.array(initial_guess)\n",
    "    num_samples = len(dataset)\n",
    "    for _ in range(max_iterations):\n",
    "        np.random.shuffle(dataset)  # Randomly shuffled the dataset\n",
    "        for data_point in dataset:\n",
    "            grad = df(x, data_point)\n",
    "            if np.linalg.norm(grad) < epsilon:\n",
    "                break\n",
    "            x = x - lr * grad\n",
    "    return x, f(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be4b4687-a6a0-482b-9b1b-f0e13e4241e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.99999994] [34.]\n"
     ]
    }
   ],
   "source": [
    "initial_guess = [6]\n",
    "dataset = np.arange(8)\n",
    "\n",
    "optim_param, min_value = sgd(f, df, initial_guess, dataset)\n",
    "\n",
    "print(optim_param, min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded751d4-29cf-4e29-a981-9a8318cf2ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ea48103-7b51-405b-b2fd-74cfb302335e",
   "metadata": {},
   "source": [
    "### Mini-Batch Gradient Descent\n",
    "\n",
    "Since mini-batch gradient descent combines the ideas of batch gradient descent with SGD, it is the preferred technique. It divides the training dataset into manageable groups and updates each separately. This strikes a balance between batch gradient descent’s effectiveness and stochastic gradient descent’s durability.\n",
    "\n",
    "Mini-batch sizes typically range from 50 to 256, although, like with other machine learning techniques, there is no set standard because it depends on the application. The most popular kind in deep learning, this method is used when training a neural network.\n",
    "\n",
    "#### Advantages\n",
    "- The model is updated more frequently than the stack gradient descent method, allowing for more robust convergence and avoiding local minima.\n",
    "- Batch updates provide a more computationally efficient process than stochastic gradient descent.\n",
    "- Batch processing allows for both the efficiency of not having all the training data in memory and implementing the algorithm.\n",
    "#### Disadvantages\n",
    "- Mini-batch requires additional hyperparameters “mini-batch size” to be set for the learning algorithm.\n",
    "- Error information should be accumulated over a mini-batch of training samples, such as batch gradient descent.\n",
    "- it will generate complex functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ceea7a9-c2fc-40c0-8259-44033aa57946",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.sin(x**2)\n",
    "    \n",
    "def df(x, batch):\n",
    "    return np.cos(x**2) * 2 * x * batch.mean()   # We are multiplying the error of the batch with respect to x\n",
    "\n",
    "def mini_batch_gradient_descent(f, df, intial_guess, dataset, batch_size=2, lr=0.01, epsilon=1e-6, max_iterations=10000):\n",
    "    \"\"\"\n",
    "    Mini-batch Gradient Descent optimization algorithm.\n",
    "    \n",
    "    Args:\n",
    "    f (function): The objective function to minimize.\n",
    "    df (function): The gradient (derivative) of the objective function.\n",
    "    initial_guess (array_like): Initial guess for the parameters.\n",
    "    dataset (array_like): The dataset for mini-batch updates.\n",
    "    batch_size (int): Size of mini-batch (default 32).\n",
    "    learning_rate (float): Learning rate or step size for the update (default 0.01).\n",
    "    epsilon (float): Convergence criterion. The algorithm stops when the change in\n",
    "        the value of the objective function is less than epsilon (default 1e-6).\n",
    "    max_iterations (int): Maximum number of iterations (default 1000).\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the optimized parameters and the value of the objective function at the optimum.\n",
    "    \"\"\"\n",
    "    x = np.array(initial_guess)\n",
    "    num_samples = len(dataset)\n",
    "    for _ in range(max_iterations):\n",
    "        np.random.shuffle(dataset)\n",
    "        # Selecting a window of batch size\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch = dataset[i:i+batch_size]\n",
    "            grad = df(x, batch)\n",
    "            if np.linalg.norm(grad) < epsilon:\n",
    "                break\n",
    "            x = x - lr * grad\n",
    "    return x, f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "efa61a62-d1eb-4068-baf0-8747c9f373e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.85406478] [-1.]\n"
     ]
    }
   ],
   "source": [
    "intial_guess = [1]\n",
    "dataset = np.arange(6)\n",
    "\n",
    "optim_param, min_value = mini_batch_gradient_descent(f, df, intial_guess, dataset)\n",
    "\n",
    "print(optim_param, min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61e877-eb36-4458-ae98-8400e8d902a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0742f5d-b0d0-418c-bc83-8d4bc4ee55c3",
   "metadata": {},
   "source": [
    "### Momentum Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ad22b549-fc8d-4aaa-b78f-ad1b7606ce42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2 - 5*x\n",
    "\n",
    "def df(x):\n",
    "    return 2*x - 5\n",
    "\n",
    "def momentum_gradient_descent(f, df, initial_guess, learning_rate=0.01, momentum=0.9, epsilon=1e-6, max_iterations=1000):\n",
    "    \"\"\"\n",
    "    Momentum Gradient Descent optimization algorithm.\n",
    "    \n",
    "    Args:\n",
    "    f (function): The objective function to maximize.\n",
    "    df (function): The gradient (derivative) of the objective function.\n",
    "    initial_guess (array_like): Initial guess for the parameters.\n",
    "    learning_rate (float): Learning rate or step size for the update (default 0.01).\n",
    "    momentum (float): Momentum parameter to accelerate convergence (default 0.9).\n",
    "    epsilon (float): Convergence criterion. The algorithm stops when the change in\n",
    "        the value of the objective function is less than epsilon (default 1e-6).\n",
    "    max_iterations (int): Maximum number of iterations (default 1000).\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the optimized parameters and the value of the objective function at the optimum.\n",
    "    \"\"\"\n",
    "    x = np.array(initial_guess, dtype=np.float64)\n",
    "    velocity = np.array([0])\n",
    "    for itr in range(max_iterations):\n",
    "        gradient = df(x)\n",
    "        velocity = momentum * velocity - learning_rate * gradient\n",
    "        print(f\"itr: {itr}, velocity:{velocity}, gradient: {gradient}\")\n",
    "        if np.linalg.norm(gradient) < epsilon:\n",
    "            break\n",
    "        x += velocity \n",
    "    return x, f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a7f8ec4a-874a-4232-b775-bf147e514138",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itr: 0, velocity:[0.03], gradient: [-3.]\n",
      "itr: 1, velocity:[0.0564], gradient: [-2.94]\n",
      "itr: 2, velocity:[0.079032], gradient: [-2.8272]\n",
      "itr: 3, velocity:[0.09782016], gradient: [-2.669136]\n",
      "itr: 4, velocity:[0.1127731], gradient: [-2.47349568]\n",
      "itr: 5, velocity:[0.12397529], gradient: [-2.24794948]\n",
      "itr: 6, velocity:[0.13157775], gradient: [-1.99999891]\n",
      "itr: 7, velocity:[0.13578841], gradient: [-1.73684342]\n",
      "itr: 8, velocity:[0.13686223], gradient: [-1.4652666]\n",
      "itr: 9, velocity:[0.13509143], gradient: [-1.19154214]\n",
      "itr: 10, velocity:[0.13079588], gradient: [-0.92135928]\n",
      "itr: 11, velocity:[0.12431397], gradient: [-0.65976752]\n",
      "itr: 12, velocity:[0.11599397], gradient: [-0.41113959]\n",
      "itr: 13, velocity:[0.10618609], gradient: [-0.17915166]\n",
      "itr: 14, velocity:[0.09523527], gradient: [0.03322051]\n",
      "itr: 15, velocity:[0.08347483], gradient: [0.22369106]\n",
      "itr: 16, velocity:[0.07122094], gradient: [0.39064072]\n",
      "itr: 17, velocity:[0.05876802], gradient: [0.53308261]\n",
      "itr: 18, velocity:[0.04638503], gradient: [0.65061866]\n",
      "itr: 19, velocity:[0.03431264], gradient: [0.74338873]\n",
      "itr: 20, velocity:[0.02276124], gradient: [0.81201401]\n",
      "itr: 21, velocity:[0.01190975], gradient: [0.85753649]\n",
      "itr: 22, velocity:[0.00190522], gradient: [0.88135599]\n",
      "itr: 23, velocity:[-0.00713697], gradient: [0.88516642]\n",
      "itr: 24, velocity:[-0.0151322], gradient: [0.87089248]\n",
      "itr: 25, velocity:[-0.02202526], gradient: [0.84062809]\n",
      "itr: 26, velocity:[-0.02778851], gradient: [0.79657757]\n",
      "itr: 27, velocity:[-0.03241966], gradient: [0.74100055]\n",
      "itr: 28, velocity:[-0.03593931], gradient: [0.67616122]\n",
      "itr: 29, velocity:[-0.0383882], gradient: [0.6042826]\n",
      "itr: 30, velocity:[-0.03982445], gradient: [0.52750619]\n",
      "itr: 31, velocity:[-0.04032057], gradient: [0.4478573]\n",
      "itr: 32, velocity:[-0.03996068], gradient: [0.36721615]\n",
      "itr: 33, velocity:[-0.03883756], gradient: [0.2872948]\n",
      "itr: 34, velocity:[-0.03705], gradient: [0.20961968]\n",
      "itr: 35, velocity:[-0.0347002], gradient: [0.13551968]\n",
      "itr: 36, velocity:[-0.03189137], gradient: [0.06611929]\n",
      "itr: 37, velocity:[-0.0287256], gradient: [0.00233655]\n",
      "itr: 38, velocity:[-0.02530189], gradient: [-0.05511465]\n",
      "itr: 39, velocity:[-0.02171452], gradient: [-0.10571843]\n",
      "itr: 40, velocity:[-0.01805159], gradient: [-0.14914747]\n",
      "itr: 41, velocity:[-0.01439393], gradient: [-0.18525065]\n",
      "itr: 42, velocity:[-0.01081415], gradient: [-0.21403851]\n",
      "itr: 43, velocity:[-0.00737607], gradient: [-0.2356668]\n",
      "itr: 44, velocity:[-0.00413427], gradient: [-0.25041893]\n",
      "itr: 45, velocity:[-0.00113397], gradient: [-0.25868747]\n",
      "itr: 46, velocity:[0.00158898], gradient: [-0.26095541]\n",
      "itr: 47, velocity:[0.00400786], gradient: [-0.25777744]\n",
      "itr: 48, velocity:[0.00610469], gradient: [-0.24976172]\n",
      "itr: 49, velocity:[0.00786974], gradient: [-0.23755234]\n",
      "itr: 50, velocity:[0.0093009], gradient: [-0.22181285]\n",
      "itr: 51, velocity:[0.01040292], gradient: [-0.20321106]\n",
      "itr: 52, velocity:[0.01118668], gradient: [-0.18240522]\n",
      "itr: 53, velocity:[0.01166833], gradient: [-0.16003186]\n",
      "itr: 54, velocity:[0.01186845], gradient: [-0.1366952]\n",
      "itr: 55, velocity:[0.01181119], gradient: [-0.1129583]\n",
      "itr: 56, velocity:[0.01152343], gradient: [-0.08933592]\n",
      "itr: 57, velocity:[0.01103398], gradient: [-0.06628907]\n",
      "itr: 58, velocity:[0.01037279], gradient: [-0.04422112]\n",
      "itr: 59, velocity:[0.00957027], gradient: [-0.02347554]\n",
      "itr: 60, velocity:[0.00865659], gradient: [-0.00433501]\n",
      "itr: 61, velocity:[0.00766115], gradient: [0.01297817]\n",
      "itr: 62, velocity:[0.00661203], gradient: [0.02830047]\n",
      "itr: 63, velocity:[0.00553558], gradient: [0.04152453]\n",
      "itr: 64, velocity:[0.00445607], gradient: [0.05259569]\n",
      "itr: 65, velocity:[0.00339538], gradient: [0.06150782]\n",
      "itr: 66, velocity:[0.00237286], gradient: [0.06829858]\n",
      "itr: 67, velocity:[0.00140513], gradient: [0.0730443]\n",
      "itr: 68, velocity:[0.00050607], gradient: [0.07585455]\n",
      "itr: 69, velocity:[-0.0003132], gradient: [0.07686669]\n",
      "itr: 70, velocity:[-0.00104429], gradient: [0.07624029]\n",
      "itr: 71, velocity:[-0.00168137], gradient: [0.07415171]\n",
      "itr: 72, velocity:[-0.00222113], gradient: [0.07078896]\n",
      "itr: 73, velocity:[-0.00266248], gradient: [0.06634671]\n",
      "itr: 74, velocity:[-0.00300645], gradient: [0.06102175]\n",
      "itr: 75, velocity:[-0.00325589], gradient: [0.05500885]\n",
      "itr: 76, velocity:[-0.00341528], gradient: [0.04849706]\n",
      "itr: 77, velocity:[-0.00349041], gradient: [0.04166651]\n",
      "itr: 78, velocity:[-0.00348823], gradient: [0.03468568]\n",
      "itr: 79, velocity:[-0.0034165], gradient: [0.02770922]\n",
      "itr: 80, velocity:[-0.00328361], gradient: [0.02087623]\n",
      "itr: 81, velocity:[-0.00309834], gradient: [0.01430901]\n",
      "itr: 82, velocity:[-0.00286963], gradient: [0.00811233]\n",
      "itr: 83, velocity:[-0.0026064], gradient: [0.00237307]\n",
      "itr: 84, velocity:[-0.00231736], gradient: [-0.00283972]\n",
      "itr: 85, velocity:[-0.00201088], gradient: [-0.00747444]\n",
      "itr: 86, velocity:[-0.00169483], gradient: [-0.0114962]\n",
      "itr: 87, velocity:[-0.00137649], gradient: [-0.01488586]\n",
      "itr: 88, velocity:[-0.00106245], gradient: [-0.01763883]\n",
      "itr: 89, velocity:[-0.00075857], gradient: [-0.01976373]\n",
      "itr: 90, velocity:[-0.0004699], gradient: [-0.02128087]\n",
      "itr: 91, velocity:[-0.00020071], gradient: [-0.02222068]\n",
      "itr: 92, velocity:[4.55857186e-05], gradient: [-0.02262209]\n",
      "itr: 93, velocity:[0.00026634], gradient: [-0.02253092]\n",
      "itr: 94, velocity:[0.00045969], gradient: [-0.02199824]\n",
      "itr: 95, velocity:[0.00062451], gradient: [-0.02107887]\n",
      "itr: 96, velocity:[0.00076035], gradient: [-0.01982986]\n",
      "itr: 97, velocity:[0.00086741], gradient: [-0.01830916]\n",
      "itr: 98, velocity:[0.00094641], gradient: [-0.01657434]\n",
      "itr: 99, velocity:[0.00099859], gradient: [-0.01468151]\n",
      "itr: 100, velocity:[0.00102557], gradient: [-0.01268434]\n",
      "itr: 101, velocity:[0.00102935], gradient: [-0.0106332]\n",
      "itr: 102, velocity:[0.00101216], gradient: [-0.00857451]\n",
      "itr: 103, velocity:[0.00097644], gradient: [-0.0065502]\n",
      "itr: 104, velocity:[0.00092477], gradient: [-0.00459731]\n",
      "itr: 105, velocity:[0.00085977], gradient: [-0.00274777]\n",
      "itr: 106, velocity:[0.00078408], gradient: [-0.00102822]\n",
      "itr: 107, velocity:[0.00070027], gradient: [0.00053993]\n",
      "itr: 108, velocity:[0.00061084], gradient: [0.00194047]\n",
      "itr: 109, velocity:[0.00051813], gradient: [0.00316215]\n",
      "itr: 110, velocity:[0.00042434], gradient: [0.00419841]\n",
      "itr: 111, velocity:[0.00033143], gradient: [0.00504708]\n",
      "itr: 112, velocity:[0.00024119], gradient: [0.00570995]\n",
      "itr: 113, velocity:[0.00015515], gradient: [0.00619232]\n",
      "itr: 114, velocity:[7.46056785e-05], gradient: [0.00650262]\n",
      "itr: 115, velocity:[6.26831964e-07], gradient: [0.00665183]\n",
      "itr: 116, velocity:[-6.59666666e-05], gradient: [0.00665308]\n",
      "itr: 117, velocity:[-0.00012458], gradient: [0.00652115]\n",
      "itr: 118, velocity:[-0.00017484], gradient: [0.00627199]\n",
      "itr: 119, velocity:[-0.00021658], gradient: [0.0059223]\n",
      "itr: 120, velocity:[-0.00024982], gradient: [0.00548914]\n",
      "itr: 121, velocity:[-0.00027473], gradient: [0.00498951]\n",
      "itr: 122, velocity:[-0.00029166], gradient: [0.00444005]\n",
      "itr: 123, velocity:[-0.00030106], gradient: [0.00385674]\n",
      "itr: 124, velocity:[-0.0003035], gradient: [0.00325462]\n",
      "itr: 125, velocity:[-0.00029962], gradient: [0.00264762]\n",
      "itr: 126, velocity:[-0.00029015], gradient: [0.00204837]\n",
      "itr: 127, velocity:[-0.00027581], gradient: [0.00146808]\n",
      "itr: 128, velocity:[-0.0002574], gradient: [0.00091646]\n",
      "itr: 129, velocity:[-0.00023567], gradient: [0.00040167]\n",
      "itr: 130, velocity:[-0.00021141], gradient: [-6.96792747e-05]\n",
      "itr: 131, velocity:[-0.00018534], gradient: [-0.0004925]\n",
      "itr: 132, velocity:[-0.00015818], gradient: [-0.00086318]\n",
      "itr: 133, velocity:[-0.00013056], gradient: [-0.00117954]\n",
      "itr: 134, velocity:[-0.0001031], gradient: [-0.00144066]\n",
      "itr: 135, velocity:[-7.63219593e-05], gradient: [-0.00164686]\n",
      "itr: 136, velocity:[-5.06946835e-05], gradient: [-0.00179951]\n",
      "itr: 137, velocity:[-2.66162416e-05], gradient: [-0.0019009]\n",
      "itr: 138, velocity:[-4.4133191e-06], gradient: [-0.00195413]\n",
      "itr: 139, velocity:[1.56575776e-05], gradient: [-0.00196296]\n",
      "itr: 140, velocity:[3.3408233e-05], gradient: [-0.00193164]\n",
      "itr: 141, velocity:[4.87156582e-05], gradient: [-0.00186482]\n",
      "itr: 142, velocity:[6.15180278e-05], gradient: [-0.00176739]\n",
      "itr: 143, velocity:[7.18097998e-05], gradient: [-0.00164436]\n",
      "itr: 144, velocity:[7.96361987e-05], gradient: [-0.00150074]\n",
      "itr: 145, velocity:[8.50872336e-05], gradient: [-0.00134147]\n",
      "itr: 146, velocity:[8.82914204e-05], gradient: [-0.00117129]\n",
      "itr: 147, velocity:[8.94093602e-05], gradient: [-0.00099471]\n",
      "itr: 148, velocity:[8.86273187e-05], gradient: [-0.00081589]\n",
      "itr: 149, velocity:[8.6150935e-05], gradient: [-0.00063863]\n",
      "itr: 150, velocity:[8.2199171e-05], gradient: [-0.00046633]\n",
      "itr: 151, velocity:[7.69986e-05], gradient: [-0.00030193]\n",
      "itr: 152, velocity:[7.0778114e-05], gradient: [-0.00014794]\n",
      "itr: 153, velocity:[6.37641144e-05], gradient: [-6.38117859e-06]\n",
      "itr: 154, velocity:[5.61762325e-05], gradient: [0.00012115]\n",
      "itr: 155, velocity:[4.82236141e-05], gradient: [0.0002335]\n",
      "itr: 156, velocity:[4.01017852e-05], gradient: [0.00032995]\n",
      "itr: 157, velocity:[3.19901036e-05], gradient: [0.00041015]\n",
      "itr: 158, velocity:[2.4049788e-05], gradient: [0.00047413]\n",
      "itr: 159, velocity:[1.64225082e-05], gradient: [0.00052223]\n",
      "itr: 160, velocity:[9.22950628e-06], gradient: [0.00055508]\n",
      "itr: 161, velocity:[2.57121439e-06], gradient: [0.00057353]\n",
      "itr: 162, velocity:[-3.4726726e-06], gradient: [0.00057868]\n",
      "itr: 163, velocity:[-8.84271743e-06], gradient: [0.00057173]\n",
      "itr: 164, velocity:[-1.34989034e-05], gradient: [0.00055405]\n",
      "itr: 165, velocity:[-1.74194928e-05], gradient: [0.00052705]\n",
      "itr: 166, velocity:[-2.05996333e-05], gradient: [0.00049221]\n",
      "itr: 167, velocity:[-2.30497671e-05], gradient: [0.00045101]\n",
      "itr: 168, velocity:[-2.47938922e-05], gradient: [0.00040491]\n",
      "itr: 169, velocity:[-2.5867727e-05], gradient: [0.00035532]\n",
      "itr: 170, velocity:[-2.63168237e-05], gradient: [0.00030359]\n",
      "itr: 171, velocity:[-2.61946743e-05], gradient: [0.00025095]\n",
      "itr: 172, velocity:[-2.55608463e-05], gradient: [0.00019856]\n",
      "itr: 173, velocity:[-2.44791842e-05], gradient: [0.00014744]\n",
      "itr: 174, velocity:[-2.30161047e-05], gradient: [9.84838857e-05]\n",
      "itr: 175, velocity:[-2.1239011e-05], gradient: [5.24516764e-05]\n",
      "itr: 176, velocity:[-1.92148464e-05], gradient: [9.9736544e-06]\n",
      "itr: 177, velocity:[-1.70088014e-05], gradient: [-2.84560384e-05]\n",
      "itr: 178, velocity:[-1.46831848e-05], gradient: [-6.24736412e-05]\n",
      "itr: 179, velocity:[-1.22964663e-05], gradient: [-9.18400109e-05]\n",
      "itr: 180, velocity:[-9.90249019e-06], gradient: [-0.00011643]\n",
      "itr: 181, velocity:[-7.54986193e-06], gradient: [-0.00013624]\n",
      "itr: 182, velocity:[-5.28149926e-06], gradient: [-0.00015134]\n",
      "itr: 183, velocity:[-3.13434288e-06], gradient: [-0.0001619]\n",
      "itr: 184, velocity:[-1.13921527e-06], gradient: [-0.00016817]\n",
      "itr: 185, velocity:[6.79183883e-07], gradient: [-0.00017045]\n",
      "itr: 186, velocity:[2.30215944e-06], gradient: [-0.00016909]\n",
      "itr: 187, velocity:[3.71679426e-06], gradient: [-0.00016449]\n",
      "itr: 188, velocity:[4.9156297e-06], gradient: [-0.00015705]\n",
      "itr: 189, velocity:[5.89626901e-06], gradient: [-0.00014722]\n",
      "itr: 190, velocity:[6.66091901e-06], gradient: [-0.00013543]\n",
      "itr: 191, velocity:[7.21588563e-06], gradient: [-0.00012211]\n",
      "itr: 192, velocity:[7.57103787e-06], gradient: [-0.00010767]\n",
      "itr: 193, velocity:[7.73925413e-06], gradient: [-9.25320049e-05]\n",
      "itr: 194, velocity:[7.73586369e-06], gradient: [-7.70534966e-05]\n",
      "itr: 195, velocity:[7.57809501e-06], gradient: [-6.15817692e-05]\n",
      "itr: 196, velocity:[7.2845413e-06], gradient: [-4.64255792e-05]\n",
      "itr: 197, velocity:[6.87465214e-06], gradient: [-3.18564966e-05]\n",
      "itr: 198, velocity:[6.36825885e-06], gradient: [-1.81071923e-05]\n",
      "itr: 199, velocity:[5.78513971e-06], gradient: [-5.37067465e-06]\n",
      "itr: 200, velocity:[5.14462969e-06], gradient: [6.19960477e-06]\n",
      "itr: 201, velocity:[4.46527808e-06], gradient: [1.64888642e-05]\n",
      "itr: 202, velocity:[3.76455607e-06], gradient: [2.54194203e-05]\n",
      "itr: 203, velocity:[3.05861514e-06], gradient: [3.29485324e-05]\n",
      "itr: 204, velocity:[2.362096e-06], gradient: [3.90657627e-05]\n",
      "itr: 205, velocity:[1.68798685e-06], gradient: [4.37899547e-05]\n",
      "itr: 206, velocity:[1.04752888e-06], gradient: [4.71659284e-05]\n",
      "itr: 207, velocity:[4.50166131e-07], gradient: [4.92609862e-05]\n",
      "itr: 208, velocity:[-9.64636668e-08], gradient: [5.01613184e-05]\n",
      "itr: 209, velocity:[-5.86501211e-07], gradient: [4.99683911e-05]\n",
      "itr: 210, velocity:[-1.01580498e-06], gradient: [4.87953887e-05]\n",
      "itr: 211, velocity:[-1.38186227e-06], gradient: [4.67637787e-05]\n",
      "itr: 212, velocity:[-1.68367658e-06], gradient: [4.40000542e-05]\n",
      "itr: 213, velocity:[-1.92163593e-06], gradient: [4.0632701e-05]\n",
      "itr: 214, velocity:[-2.09736663e-06], gradient: [3.67894292e-05]\n",
      "itr: 215, velocity:[-2.21357693e-06], gradient: [3.25946959e-05]\n",
      "itr: 216, velocity:[-2.27389466e-06], gradient: [2.8167542e-05]\n",
      "itr: 217, velocity:[-2.28270272e-06], gradient: [2.36197527e-05]\n",
      "itr: 218, velocity:[-2.24497592e-06], gradient: [1.90543473e-05]\n",
      "itr: 219, velocity:[-2.16612228e-06], gradient: [1.45643955e-05]\n",
      "itr: 220, velocity:[-2.05183156e-06], gradient: [1.02321509e-05]\n",
      "itr: 221, velocity:[-1.90793328e-06], gradient: [6.12848777e-06]\n",
      "itr: 222, velocity:[-1.74026617e-06], gradient: [2.31262121e-06]\n",
      "itr: 223, velocity:[-1.55456044e-06], gradient: [-1.16791113e-06]\n",
      "itr: 224, velocity:[-1.35633408e-06], gradient: [-4.27703201e-06]\n",
      "itr: 225, velocity:[-1.15080367e-06], gradient: [-6.98970016e-06]\n",
      "itr: 226, velocity:[-9.42810225e-07], gradient: [-9.29130749e-06]\n",
      "itr: 227, velocity:[-7.36759923e-07], gradient: [-1.11769279e-05]\n",
      "itr: 228, velocity:[-5.36579453e-07], gradient: [-1.26504478e-05]\n",
      "itr: 229, velocity:[-3.45685441e-07], gradient: [-1.37236067e-05]\n",
      "itr: 230, velocity:[-1.66967121e-07], gradient: [-1.44149776e-05]\n",
      "itr: 231, velocity:[-2.78129056e-09], gradient: [-1.47489118e-05]\n",
      "itr: 232, velocity:[1.45041582e-07], gradient: [-1.47544744e-05]\n",
      "itr: 233, velocity:[2.75181336e-07], gradient: [-1.44643912e-05]\n",
      "itr: 234, velocity:[3.86803488e-07], gradient: [-1.39140286e-05]\n",
      "itr: 235, velocity:[4.79527355e-07], gradient: [-1.31404216e-05]\n",
      "itr: 236, velocity:[5.53388289e-07], gradient: [-1.21813669e-05]\n",
      "itr: 237, velocity:[6.08795363e-07], gradient: [-1.10745903e-05]\n",
      "itr: 238, velocity:[6.46485822e-07], gradient: [-9.85699957e-06]\n",
      "itr: 239, velocity:[6.67477519e-07], gradient: [-8.56402792e-06]\n",
      "itr: 240, velocity:[6.73020496e-07], gradient: [-7.22907289e-06]\n",
      "itr: 241, velocity:[6.64548765e-07], gradient: [-5.88303189e-06]\n",
      "itr: 242, velocity:[6.43633232e-07], gradient: [-4.55393436e-06]\n",
      "itr: 243, velocity:[6.11936588e-07], gradient: [-3.2666679e-06]\n",
      "itr: 244, velocity:[5.71170877e-07], gradient: [-2.04279472e-06]\n",
      "itr: 245, velocity:[5.23058319e-07], gradient: [-9.00452968e-07]\n"
     ]
    }
   ],
   "source": [
    "initial_guess = [5]\n",
    "\n",
    "optim_param, min_value = momentum_gradient_descent(f, df, intial_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3acdfd4-f031-4403-9f9a-d1236b5fc384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
